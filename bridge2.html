<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"> 
  </head>
  <body>
    <div id="renkon">
      <link rel="stylesheet" href="../bridge/session.css" />
      <script type="reactive">
        const localMediaModule = import("../bridge/localmedia.js");
        const {audioBufferToWav} = import("../bridge/wav.js");

        const {ReflectCommands} = import("https://substrate.home.arpa/tool-call/js/commands.js");
        const r = new ReflectCommands("https://substrate.home.arpa").reflect();
        console.log(r);

        // const result = r["faster-whisper:transcribe-data"].run({audio_data: "base64encodedfile", audio_metadata: {mime_type: "audio/wav"}, task: 'transcribe'})

        const {html, render} = import('../preact.standalone.module.js');
        const setSessionButton = Events.listener(document.querySelector("#setSessionButton"), "click", (evt) => evt);
        const audioContext = Behaviors.keep(Events.listener(document.querySelector("#logo"), "click", (evt) => new window.AudioContext()));

        console.log("audioContext", audioContext);
        const sessionSpec = (() => document.querySelector("#sessionName").textContent)(setSessionButton);

        const localMedia = new localMediaModule.LocalMedia({
          videoSource: false,
          onstreamchange: (stream) => {
          }
        });

        const streams = localMedia.setup();

        const source = ((audioContext, localMedia, _streams) => {
          console.log("in source", audioContext, localMedia);
          return new window.MediaStreamAudioSourceNode(audioContext, {mediaStream: localMedia.stream})
        })(audioContext, localMedia, streams);

        const processor = ((audioContext) => {
            return audioContext.audioWorklet.addModule(`../bridge/audio-visualizer.js`).then(() => {
                return new window.AudioWorkletNode(audioContext, "processor");
            });
        })(audioContext);

        console.log(processor);

        const input = Events.observe((notifier) => {
            processor.port.onmessage = (event) => {
                notifier(event.data.input);
            }
            source.connect(processor);
            return () => source.disconnect(processor);
        });

        const longerBuffer = Behaviors.collect([], Events.or(input, consumer), (old, now) => {
            if (now.consumed) {
                return [];
            }

            console.log("longerBuffer.length", [...old, now].length);
            return [...old, now];     
        });

        const consumer = Events.collect(undefined, $longerBuffer, (old, now) => {
            const zip = (pairs) => {
                const a = [];
                const b = [];
                for (const pair of pairs) {
                    a.push(pair[0]);
                    b.push(pair[1]);
                }
                return [a, b];
            }
            if (now.length >= 64) {
                return {data: zip(now), consumed: true};
            }
            return undefined;
        });

        const wav = ((consumer) => {
            if (consumer && consumer.consumed) {
                return audioBufferToWav(16000, consumer.data);
            }
            return;
        })(consumer);
        console.log("wav", wav);
    
        const result = r["faster-whisper:transcribe-data"].run({audio_data: btoa(wav), audio_metadata: {mime_type: "audio/wav"}, task: 'transcribe'})


      </script>
      <canvas id="oscilloscope" width=320 height=320></canvas>
      <div class="flex flex-wrap align-center px-6 py-4">
        <h1 id="logo" class="py-1 text-xl font-bold grow">bridge</h1>
      </div>
      <div id="sessionNameHolder">
        <div contentEditable id="sessionName">https://substrate.home.arpa/bridge;sessions=sp-01J343NFDMW9B5XG6S6XJZDNE8;id=cqcqi10ri6qs739svkk1</div>
        <button id="setSessionButton">Set</button>
      </div>
      <div id="sessions"></div>
    </div>

    </div>
    <script type="module">
      import("./renkon.js").then((mod) => mod.view());
    </script>
  </body>
</html>
