<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"> 
  </head>
  <body>
    <div id="renkon">
      <link rel="stylesheet" href="./bridge/session.css">
      <script type="reactive">
        const localMediaModule = import("../bridge/localmedia.js");
        const {audioBufferToWav} = import("../bridge/wav.js");
        const {toBase64} = import("../bridge/toBase64.js");

        const {html, render} = import('../preact.standalone.module.js');
        const audioContext = Behaviors.keep(Events.listener(document.querySelector("#logo"), "click", (evt) => new window.AudioContext()));

        const localMedia = (() => new localMediaModule.LocalMedia({
          videoSource: false,
          onstreamchange: (stream) => {
          }
        }))(audioContext);

        const streams = localMedia.setup();

        const source = ((audioContext, localMedia, _streams) => {
          console.log("in source", audioContext, localMedia);
          return new window.MediaStreamAudioSourceNode(audioContext, {mediaStream: localMedia.stream})
        })(audioContext, localMedia, streams);

        const processor = ((audioContext) => {
            return audioContext.audioWorklet.addModule(`../bridge/audio-samples.js`).then(() => {
                const worklet = new window.AudioWorkletNode(audioContext, "processor");
                worklet.addEventListener("processorerror", console.log);
                return worklet;
            })
        })(audioContext, source);

        console.log(processor);

        const inputs = Events.observe((notifier) => {
            processor.port.onmessage = (event) => {
                notifier(event.data);
            }
            source.connect(processor);
            return () => source.disconnect(processor);
        }, {queued: true});

        const voiceChunk = Events.receiver();

        console.log("voiceChunk", voiceChunk);

        // {label: number, data: Array<[Array<number>, Array<number>]>}
        const longerBuffer = Behaviors.collect({label: 1, data: []}, inputs, (old, inputs) => {
            const newData = inputs.map(obj => obj.input);
            if (old.data.length < 1280) {
                old.data.push(...newData); // could be a bad idea
                return old;
            } else {
                const newId = old.label + 1;
                Events.send(voiceChunk, old);
                return {label: newId, data: [...newData]};
            }
        });

        const wav = ((voiceChunk) => {
            const zip = (pairs) => {
                const length = pairs[0][0].length * pairs.length;
                const a = new Float32Array(length);
                const b = new Float32Array(length);
                let index = 0;
                for (let i = 0; i < pairs.length; i++) {
                    a.set(pairs[i][0], index);
                    b.set(pairs[i][1], index);
                    index += pairs[i][0].length;
                }
                return [a, b];
            }
            return {label: voiceChunk.label, wav: audioBufferToWav(44100, zip(voiceChunk.data))};
        })(voiceChunk);
        console.log("wav", wav);

        const emit = fetch("http://localhost:8888/audio", {
                method: "POST",
                mode: "cors",
                headers: {
                    "Content-Type": "application/json",                      
                },
                body: JSON.stringify({audio_data: toBase64(new Uint8Array(wav.wav)), audio_metadata: {mime_type: "audio/wav"}, task: "transcribe"})
        });

        const socket = (() => new WebSocket("http://localhost:8889"))(audioContext);

        const socketData = Events.observe((notify) => {
          socket.onmessage = (e) => {
            notify(JSON.parse(e.data))
          }
          return () => socket.close();
        });

        console.log("socketData", socketData);

        const transcriptions = Behaviors.collect([], socketData, (old, now) => {
            return [...old, socketData];
        });
        const results = transcriptions.map((transcript) => {
            return html`<div id="transcript-${transcript.label}">${transcript.segments.map((seg) => seg.text)}</div>`;
        })
        render(results, document.querySelector("#entries"));

      </script>
      <div class="flex flex-col grow">
        <button id="logo" class="py-1 text-xl font-bold grow">Start</button>
        <div id="mic-controls" class="flex space-x-2">
          <div id="mic-container"></div>
          <button name="mic-mute" id="mic-mute" class="p-2 border border-gray-600 rounded-md text-md focus:border-blue-500 focus:ring-blue-500 bg-gray-700 text-gray-400">Mute</button>
          <button id="system-audio" class="p-2 border border-gray-600 rounded-md text-md focus:border-blue-500 focus:ring-blue-500 bg-gray-700 text-gray-400">Send System Audio</button>
        </div>
      </div>
      <div id="entries" style="height:100%; overflow: scroll"></div>
    </div>
    <script type="module">
      import("./renkon.js").then((mod) => mod.view());
    </script>
  </body>
</html>
