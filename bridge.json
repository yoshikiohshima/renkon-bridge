{"padTitle":"Bridge",
"positions":{"map":{"__map":true,
"values":[["1",{"height":2756.6520000107166,
"id":"1",
"type":"resize",
"width":827.0822339072696,
"x":-560.1166586818549,
"y":-83.89870638139377}],["18",{"height":1466.393849933964,
"id":"18",
"type":"resize",
"width":935.4136523002136,
"x":486.1991708574302,
"y":-89.17549794316496}],["53",{"height":815.1473531194417,
"id":"53",
"type":"resize",
"width":717.1853855197904,
"x":-1379.6658266933164,
"y":-88.4020723640512}]]}},
"titles":{"map":{"__map":true,
"values":[["1",{"id":"1",
"state":false,
"title":"Service Access"}],["18",{"id":"18",
"state":false,
"title":"App"}],["53",{"id":"53",
"state":false,
"title":"WAV"}]]}},
"version":2,
"windowEnabled":{"map":{"__map":true,
"values":[["53",{"enabled":true,
"id":"53"}],["1",{"enabled":true,
"id":"1"}],["18",{"enabled":true,
"id":"18"}]]}},
"windowTypes":{"map":{"__map":true,
"values":[["1","code"],["18","code"],["53","code"]]}},
"windows":["1","18","53"],
"zIndex":{"map":{"__map":true,
"values":[["1",104],["18",105],["53",103]]}}}
{__codeMap: true, value: [[`1`, `const hostName = (() => {
    const maybeHost = new URL(window.top.location).searchParams.get("host");
    if (maybeHost) {
        return maybeHost;
    }
    return "/";
})();

const languages = ["eng", "en"];

const {toBase64} = import("./media/toBase64.js");
const {LocalMedia} = import("./media/localmedia.js");

const {reflect, sender} = import(\`./msg.js\`);

const msgindex = reflect(\`\${hostName}/substrate/v1/msgindex\`);
const msgSender = sender();
const sendmsg = (msg, data) => {
  return msgSender(msg, data).then((obj) => obj.data.returns);
}

const audioContext = Behaviors.collect(undefined, trigger, (old, _now) => {
    if (old === undefined) {
        return new window.AudioContext();
    }
    return old;
});

const trigger = Events.listener(document.querySelector("body"), "click", (evt) => evt);

const localMedia = new LocalMedia({
    videoSource: false,
    onstreamchange: (_stream) => {
    }
});

const streams = localMedia.setup();

const source = ((audioContext, localMedia, _streams) => {
    // console.log("in source", audioContext, localMedia);
    return new window.MediaStreamAudioSourceNode(audioContext, {mediaStream: localMedia.stream})
})(audioContext, localMedia, streams);

const processor = ((audioContext) => {
    return audioContext.audioWorklet.addModule(\`./media/audio-samples.js\`).then(() => {
        const worklet = new window.AudioWorkletNode(audioContext, "processor");
        worklet.addEventListener("processorerror", console.log);
        return worklet;
    })
})(audioContext);

const inputs = Events.observe((notifier) => {
    processor.port.onmessage = (event) => {
        notifier(event.data);
    }
    source.connect(processor);
    return () => source.disconnect(processor);
}, {queued: true});

const voiceChunk = Events.receiver();

console.log("voiceChunk", voiceChunk);

const _speaking = Behaviors.collect({time: 0, data: [], speaking: false}, inputs, ((old, current) => {
    const max = Math.max(...current.map((c) => c.max));
    const currentTime = current[current.length - 1].currentTime;
    const newInput = current.map((c) => c.input);

    if (old.speaking) {
        const newData = [...old.data, ...newInput];
        if (max < 0.01) {
            if (currentTime > old.time + 0.5) {
                Events.send(voiceChunk, {time: currentTime, data: newData});
                return {time: currentTime, data: newData, speaking: false};
            }
            return {time: old.time, data: newData, speaking: old.speaking};
        }
        return {time: currentTime, data: newData, speaking: old.speaking};
    }

    if (max < 0.01) {
        return old;
    }

    return {time: currentTime, data: newInput, speaking: true};
}));

const listening = Behaviors.collect({time: 0, data: [], max: 0, over: false}, inputs, ((old, current) => {
    const max = Math.max(...current.map((c) => c.max));
    const currentTime = current[current.length - 1].currentTime;
    const newInput = current.map((c) => c.input).filter((input) => input);
    const newData = old.over ? [...newInput] : [...old.data, ...newInput];
    const newTime = old.over ? currentTime : old.time;
    const newMax = old.over ? max : Math.max(old.max, max);

    if (currentTime >= old.time + 1 && !old.over) {
        if (newMax < 0.01) {
          return {time: currentTime, data: [], max: 0, over: true};
        }
        return {time: newTime, data: newData, max: newMax, over: true};
    }
    return {time: newTime, data: newData, max: newMax, over: false};
}));

const listeningChunk = listening.over ? listening : undefined;

const fasterTranscribed = ((wav) => {
    const audio_data = toBase64(new Uint8Array(wav.wav));
    const audio_metadata = {mime_type: "audio/wav"};
    const task = "transcribe";
    const parameters = {audio_data, audio_metadata, task};
    const msg = msgindex['faster-whisper/transcribe-data'];
    return sendmsg(msg, {parameters});
})(fasterWav);

const transcribed = ((wav) => {
    const audio_data = toBase64(new Uint8Array(wav.wav));
    const audio_metadata = {mime_type: "audio/wav"};
    const task = "transcribe";
    const parameters = {audio_data, audio_metadata, task};
    const msg = msgindex['faster-whisper/transcribe-data'];
    return sendmsg(msg, {parameters});
})(wav);

const sentenceId = Behaviors.collect(0, transcribed, (old, _new) => old + 1);

const transcriptionWithId = {transcribed, sentenceId};

console.log("transcriptionWithId", transcriptionWithId);

const requestTranslation = ((transcriptionWithId) => {
  if (!languages.includes(transcriptionWithId.transcribed.target_language)) {
    return transcriptionWithId;
  }
  return;
})(transcriptionWithId);
 
const translatedP = ((transcriptionWithId) => {
    const data = transcriptionWithId.transcribed;
    const words = data.segments.flatMap((seg) => seg.words);
    console.log(words);
    const parameters = {
      source_language: transcriptionWithId.transcribed.target_language,
      target_language: languages[0],
      text: words.map(w => w.word).join("")
    };
    const msg = msgindex['seamlessm4t/translate'];
    return {translated: sendmsg(msg, {parameters}), sentenceId: transcriptionWithId.sentenceId};
})(requestTranslation, msgSender, msgindex);

const translatedWithId = Events.resolvePart(translatedP);

const translations = Behaviors.collect(
  {map: new Map()},
  translatedWithId, (old, translatedWithId) => {
      console.log("translatedWithId", translatedWithId);
      const text = translatedWithId.translated.segments.map((s => s.text)).join("");
      old.map.set(translatedWithId.sentenceId, text);
      return {map: old.map};
});

console.log(translations);

const speakersFor = () => ["unknown"];

const model = Behaviors.collect([], transcriptionWithId, (old, t) => {
  const transcribed = transcriptionWithId.transcribed;
  const sentenceId = transcriptionWithId.sentenceId;
  if (transcribed.segments.length === 0) {console.log("silent"); return old;}
  const now = {
    transcript: {fields: transcribed},
    translations: [],
    assistants: [],
    tools: [],
    speakers: speakersFor(),
    sentenceId
  };
  return [...old, now];
})`],
[`18`, `const {h, render, html} = import("./preact.standalone.module.js");

(() => {
  const head = document.querySelector('head');
  const script = document.createElement('script');
  script.id = 'tailwindcss';
  script.src = 'https://cdn.tailwindcss.com';
  head.querySelector("#tailwindcss")?.remove();
  head.appendChild(script);

  const css = \`
html, body {
height: 100%
}
\`;
  const style = document.createElement("style");
  style.id = "pad-css";
  style.textContent = css;
  document.head.querySelector("#pad-css")?.remove();
  document.head.appendChild(style);
})(sessionStart);

const sessionStart = Behaviors.keep(Events.once(Date.now()));

const Topbar = h('div', {"class":"flex flex-wrap px-6 py-4","id":"topbar"},
  sessionStart ? h("h1", {"class":"py-1 text-xl font-bold"},
    sessionStart.toLocaleString(),
  ) : null,
)

const Entry = (entry, translations) => {
  if (!entry.transcript || !entry.transcript.fields || !entry.transcript.fields || !entry.transcript.fields.segments) return null;
  const data = entry.transcript.fields;
  const track = [];
  const translation = translations.map.get(entry.sentenceId);
  console.log("entry translation", translation);
  const words = data.segments
    .flatMap((seg) => seg.words);
  return h('div', null,
    h("div", {"class": "text text-teal-500 space-x-4"}, entry.speakers.length == 0 ? "unknown" : entry.speakers.map(s => {
      return h("span", {"class": \`text-\${s.color}\`, "data-speaker-id": s.id}, s.name);
    })),
    h("div", {"class": \`text text-gray-400\`, lang: data.source_language},
      words.map(w => {
        const colors = speakersFor(track, w.start*1000, w.end*1000).map(s => s.color);
        return h('span', {
          "class": colors.length == 0 ? "" : \`underline decoration-\${colors[0]}/50\`,
        }, w.word)
      })
    ),
   translation ? h("div", {"class": "text text-cyan-500", lang: translation.lang},
        translation,
      ) : null,    
    entry.assistants.map(asst => {
      return h("div", {"class": "text text-fuchsia-500 whitespace-pre-wrap"},
        h('b', null, asst.name), ' ', asst.text,
      );
    }),
  );
}

// TODO add keyed entries
const Session = (model, translations) => { return h('div', null, model.map((e) => Entry(e, translations))) };

const App = h('div', {"class": "flex flex-row bg-gray-900 text-white antialiased"},
  h('div', {'class': 'flex flex-col h-screen grow'},
    Topbar,
    h('div', {"class":"grow px-6 mt-4 overflow-auto"},
      Session(model, translations),
    ),
  ),
)

render(
  App,
  document.querySelector('body'),
)`],
[`53`, `const {audioBufferToWav} = import("./media/wav.js");

const wav = ((voiceChunk) => {
    return {timelabel: voiceChunk.time, wav: chunkToWav(voiceChunk.data)};
})(voiceChunk);

const fasterWav = ((voiceChunk) => {
    return {timelabel: voiceChunk.time, wav: chunkToWav(voiceChunk.data)};
})(listeningChunk);

console.log("wav", wav);
console.log("fasterWav", fasterWav);

const chunkToWav = (data) => {
    const zip = (pairs) => {
        const length = pairs[0][0].length * pairs.length;
        const a = new Float32Array(length);
        const b = new Float32Array(length);
        let index = 0;
        for (let i = 0; i < pairs.length; i++) {
            a.set(pairs[i][0], index);
            b.set(pairs[i][1], index);
            index += pairs[i][0].length;
        }
        return [a, b];
    };
    return audioBufferToWav(44100, zip(voiceChunk.data));
}

/*
  const saveWav = ((wav) => {
  let div = document.createElement("a");
  const blob = new Blob([wav.wav], {type: "audio/wav"});
  let fileURL = URL.createObjectURL(blob);
  div.setAttribute("href", fileURL);
  div.setAttribute("download", \`wav-\${Date.now()}.wav\`);
  div.click();
  })(wav);
*/
`]]}