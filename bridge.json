{"padTitle":"Bridge",
"positions":{"map":{"__map":true,
"values":[["1",{"height":2139.3662233947907,
"id":"1",
"type":"resize",
"width":1175.598079581964,
"x":-560.1166586818549,
"y":-83.89870638139377}],["18",{"height":1407.714075025237,
"id":"18",
"type":"move",
"width":942.8311006792607,
"x":866.4612238771008,
"y":-89.95857167233122}],["53",{"height":591.4492658201676,
"id":"53",
"type":"resize",
"width":695.8904958944581,
"x":-1379.6658266933164,
"y":-88.4020723640512}]]}},
"titles":{"map":{"__map":true,
"values":[["1",{"id":"1",
"state":false,
"title":"Service Access"}],["18",{"id":"18",
"state":false,
"title":"App"}],["53",{"id":"53",
"state":false,
"title":"WAV"}]]}},
"version":2,
"windowEnabled":{"map":{"__map":true,
"values":[["53",{"enabled":true,
"id":"53"}],["1",{"enabled":true,
"id":"1"}],["18",{"enabled":true,
"id":"18"}]]}},
"windowTypes":{"map":{"__map":true,
"values":[["1","code"],["18","code"],["53","code"]]}},
"windows":["1","18","53"],
"zIndex":{"map":{"__map":true,
"values":[["1",104],["18",103],["53",105]]}}}
{__codeMap: true, value: [[`1`, `const hostName = (() => {
    const maybeHost = new URL(window.top.location).searchParams.get("host");
    if (maybeHost) {
        return maybeHost;
    }
    return "/";
})();

const languages = ["eng", "en"];

const {toBase64} = import("./media/toBase64.js");
const {LocalMedia} = import("./media/localmedia.js");

const {reflect, sender} = import(\`./msg.js\`);

const msgindex = reflect(\`\${hostName}/substrate/v1/msgindex\`);
const msgSender = sender();

const audioContext = Behaviors.collect(undefined, trigger, (old, _now) => {
    if (old === undefined) {
        return new window.AudioContext();
    }
    return old;
});

const trigger = Events.listener(document.querySelector("body"), "click", (evt) => evt);

const localMedia = new LocalMedia({
    videoSource: false,
    onstreamchange: (_stream) => {
    }
});

const streams = localMedia.setup();

const source = ((audioContext, localMedia, _streams) => {
    // console.log("in source", audioContext, localMedia);
    return new window.MediaStreamAudioSourceNode(audioContext, {mediaStream: localMedia.stream})
})(audioContext, localMedia, streams);

const processor = ((audioContext) => {
    return audioContext.audioWorklet.addModule(\`./media/audio-samples.js\`).then(() => {
        const worklet = new window.AudioWorkletNode(audioContext, "processor");
        worklet.addEventListener("processorerror", console.log);
        return worklet;
    })
})(audioContext);

const inputs = Events.observe((notifier) => {
    processor.port.onmessage = (event) => {
        notifier(event.data);
    }
    source.connect(processor);
    return () => source.disconnect(processor);
}, {queued: true});

const voiceChunk = Events.receiver();

console.log("voiceChunk", voiceChunk);

const _speaking = Behaviors.collect({time: 0, data: [], speaking: false}, inputs, ((old, current) => {
    const max = Math.max(...current.map((c) => c.max));
    const currentTime = current[current.length - 1].currentTime;
    const newInput = current.map((c) => c.input);

    if (old.speaking) {
        const newData = [...old.data, ...newInput];
        if (max < 0.01) {
            if (currentTime > old.time + 0.5) {
                Events.send(voiceChunk, {time: currentTime, data: newData});
                return {time: currentTime, data: newData, speaking: false};
            }
            return {time: old.time, data: newData, speaking: old.speaking};
        }
        return {time: currentTime, data: newData, speaking: old.speaking};
    }

    if (max < 0.01) {
        return old;
    }

    return {time: currentTime, data: newInput, speaking: true};
}));

const sendmsg = (msg, data) => {
  return msgSender(msg, data).then((obj) => obj.data.returns);
}
const transcribed = ((wav) => {
    const audio_data = toBase64(new Uint8Array(wav.wav));
    const audio_metadata = {mime_type: "audio/wav"};
    const task = "transcribe";
    const parameters = {audio_data, audio_metadata, task};
    const msg = msgindex['faster-whisper/transcribe-data'];
    return sendmsg(msg, {parameters});
})(wav);

const sentenceId = Behaviors.collect(0, transcribed, (old, _new) => old + 1);

const transcriptionWithId = {transcribed, sentenceId};

console.log("transcriptionWithId", transcriptionWithId);

const requestTranslation = ((transcriptionWithId) => {
  if (!languages.includes(transcriptionWithId.transcribed.target_language)) {
    return transcriptionWithId;
  }
  return;
})(transcriptionWithId);
 
const translatedP = ((transcriptionWithId) => {
    const data = transcriptionWithId.transcribed;
    const words = data.segments.flatMap((seg) => seg.words);
    console.log(words);
    const parameters = {
      source_language: transcriptionWithId.transcribed.target_language,
      target_language: languages[0],
      text: words.map(w => w.word).join("")
    };
    const msg = msgindex['seamlessm4t/translate'];
    return {translated: sendmsg(msg, {parameters}), sentenceId: transcriptionWithId.sentenceId};
})(Events.change(requestTranslation), msgSender, msgindex);

const translatedWithId = Events.resolvePart(translatedP);

const translations = Behaviors.collect({map: new Map()}, translatedWithId, (old, translatedWithId) => {
    console.log("translatedWithId", translatedWithId);
  const text = translatedWithId.translated.segments.map((s => s.text)).join("");
  old.map.set(translatedWithId.sentenceId, text);
  return {map: old.map};
});

console.log(translations);

const speakersFor = () => ["unknown"];

const model = Behaviors.collect([], transcribed, (old, t) => {
  if (transcribed.segments.length === 0) {console.log("silent"); return old;}
  const now = {
    transcript: {fields: t},
    translations: [],
    assistants: [],
    tools: [],
    speakers: speakersFor(),
    sentenceId
  };
  return [...old, now];
})`],
[`18`, `const {h, render, html} = import("./preact.standalone.module.js");

(() => {
  const head = document.querySelector('head');
  const script = document.createElement('script');
  script.id = 'tailwindcss';
  script.src = 'https://cdn.tailwindcss.com';
  head.querySelector("#tailwindcss")?.remove();
  head.appendChild(script);

  const css = \`
html, body {
height: 100%
}
\`;
  const style = document.createElement("style");
  style.id = "pad-css";
  style.textContent = css;
  document.head.querySelector("#pad-css")?.remove();
  document.head.appendChild(style);
})(sessionStart);

const sessionStart = Behaviors.keep(Events.once(Date.now()));

const Topbar = h('div', {"class":"flex flex-wrap px-6 py-4","id":"topbar"},
  sessionStart ? h("h1", {"class":"py-1 text-xl font-bold"},
    sessionStart.toLocaleString(),
  ) : null,
)

const Entry = (entry, translations) => {
  if (!entry.transcript || !entry.transcript.fields || !entry.transcript.fields || !entry.transcript.fields.segments) return null;
  const data = entry.transcript.fields;
  const track = [];
  const translation = translations.map.get(entry.sentenceId);
  console.log("entry translation", translation);
  const words = data.segments
    .flatMap((seg) => seg.words);
  return h('div', null,
    h("div", {"class": "text text-teal-500 space-x-4"}, entry.speakers.length == 0 ? "unknown" : entry.speakers.map(s => {
      return h("span", {"class": \`text-\${s.color}\`, "data-speaker-id": s.id}, s.name);
    })),
    h("div", {"class": \`text text-gray-400\`, lang: data.source_language},
      words.map(w => {
        const colors = speakersFor(track, w.start*1000, w.end*1000).map(s => s.color);
        return h('span', {
          "class": colors.length == 0 ? "" : \`underline decoration-\${colors[0]}/50\`,
        }, w.word)
      })
    ),
   translation ? h("div", {"class": "text text-cyan-500", lang: translation.lang},
        translation,
      ) : null,    
    entry.assistants.map(asst => {
      return h("div", {"class": "text text-fuchsia-500 whitespace-pre-wrap"},
        h('b', null, asst.name), ' ', asst.text,
      );
    }),
  );
}

// TODO add keyed entries
const Session = (model, translations) => { return h('div', null, model.map((e) => Entry(e, translations))) };

const App = h('div', {"class": "flex flex-row bg-gray-900 text-white antialiased"},
  h('div', {'class': 'flex flex-col h-screen grow'},
    Topbar,
    h('div', {"class":"grow px-6 mt-4 overflow-auto"},
      Session(model, translations),
    ),
  ),
)

render(
  App,
  document.querySelector('body'),
)`],
[`53`, `const {audioBufferToWav} = import("./media/wav.js");

const wav = ((voiceChunk) => {
    const zip = (pairs) => {
        const length = pairs[0][0].length * pairs.length;
        const a = new Float32Array(length);
        const b = new Float32Array(length);
        let index = 0;
        for (let i = 0; i < pairs.length; i++) {
            a.set(pairs[i][0], index);
            b.set(pairs[i][1], index);
            index += pairs[i][0].length;
        }
        return [a, b];
    }
    return {timelabel: voiceChunk.time, wav: audioBufferToWav(44100, zip(voiceChunk.data))};
})(voiceChunk);


/*
  const saveWav = ((wav) => {
  let div = document.createElement("a");
  const blob = new Blob([wav.wav], {type: "audio/wav"});
  let fileURL = URL.createObjectURL(blob);
  div.setAttribute("href", fileURL);
  div.setAttribute("download", \`wav-\${Date.now()}.wav\`);
  div.click();
  })(wav);
*/
`]]}